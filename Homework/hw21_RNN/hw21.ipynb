{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PZd2TU6lUnK8"
   },
   "source": [
    "# 循环神经网络（RNN）作业"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "指导教师：胡俊峰\n",
    "\n",
    "负责助教：苏亚鲁，李浩然\n",
    "\n",
    "注意：仅需要提交.ipynb文件，请**不要**将下发压缩包中的其他文件一并交上。\n",
    "\n",
    "截止日期：6月4日24点"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第零部分"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.1 可视化工具visdom\n",
    "\n",
    "visdom是Facebook专为pytorch开发的实时可视化工具包，灵活高效且界面美观。在深度学习领域，模型训练是一个必须的过程，因此可以借助visdom实时监听并可视化一些数据，如损失值loss，正确率acc等。\n",
    "\n",
    "要使用visdom，需先完成以下步骤：\n",
    "* 在终端执行python -m visdom.server，开启监听命令；\n",
    "* 成功开启后，会返回一个网址，在浏览器里输入该网址，进入后即可显示visdom的主界面；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from visdom import Visdom \n",
    "import numpy as np\n",
    "import time\n",
    "import torch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 监听单一数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实例化一个窗口\n",
    "wind = Visdom()\n",
    "# 初始化窗口信息\n",
    "wind.line([0.], # Y的第一个点的坐标\n",
    "\t\t  [0.], # X的第一个点的坐标\n",
    "\t\t  win = 'train_loss', # 窗口的名称\n",
    "\t\t  opts = dict(title = 'train_loss') # 图像的标例\n",
    ")\n",
    "# 更新数据\n",
    "for step in range(10):\n",
    "\t# 随机获取loss,这里只是模拟实现\n",
    "\tloss = np.random.randn() * 0.5 + 2\n",
    "\twind.line([loss], [step], win = 'train_loss', update = 'append')\n",
    "\ttime.sleep(0.5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 监听多条数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实例化窗口\n",
    "wind = Visdom()\n",
    "# 初始化窗口参数\n",
    "wind.line([[0.,0.]],[0.], win = 'train', opts = dict(title = 'loss&acc', legend = ['loss','acc']))\n",
    "# 更新窗口数据\n",
    "for step in range(10):\n",
    "\tloss = 0.2 * np.random.randn() + 1\n",
    "\tacc = 0.1 * np.random.randn() + 0.5\n",
    "\twind.line([[loss, acc]], [step], win = 'train', update = 'append')\n",
    "\ttime.sleep(0.5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 可视化数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "# 加载数据集\n",
    "train_loader = torch.utils.data.DataLoader(datasets.MNIST(\n",
    "    r'mnist-data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([transforms.ToTensor()])),batch_size=128,shuffle=True)\n",
    "sample=next(iter(train_loader)) # 通过迭代器获取样本\n",
    "viz = Visdom(env='my_visual') # 注意此时创建了新环境，请在界面中选择该环境\n",
    "# sample[0]为样本数据，sample[1]为类别，nrow=16表示每行显示16张图像\n",
    "viz.images(sample[0], nrow=16, win='mnist', opts=dict(title='mnist'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.2 Pytorch中hook的使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# x,y 为leaf节点，也就是说，在计算的时候，PyTorch只会保留此节点的梯度值\n",
    "x = torch.tensor([3.], requires_grad=True)\n",
    "y = torch.tensor([5.], requires_grad=True)\n",
    "\n",
    "# a,b均为中间值，在计算梯度时，此部分会被释放掉\n",
    "a = x + y\n",
    "b = x * y\n",
    "\n",
    "c = a * b\n",
    "\n",
    "# 新建列表，用于存储Hook函数保存的中间梯度值\n",
    "a_grad = []\n",
    "def hook_grad(grad):\n",
    "    a_grad.append(grad)\n",
    "\n",
    "# register_hook的参数为一个函数\n",
    "handle = a.register_hook(hook_grad)\n",
    "c.backward()\n",
    "\n",
    "# 只有leaf节点才会有梯度值\n",
    "print('gradient:',x.grad, y.grad, a.grad, b.grad, c.grad)\n",
    "# Hook函数保留下来的中间节点a的梯度\n",
    "print('a_grad:', a_grad[0])\n",
    "# 移除Hook函数\n",
    "handle.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# 构建网络，包含一个卷积层和一个池化层\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 2, 3)\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.pool1(x)\n",
    "        return x\n",
    "# 初始化网络\n",
    "net = Net()\n",
    "# detach将张量分离\n",
    "net.conv1.weight[0].detach().fill_(1)\n",
    "net.conv1.weight[1].detach().fill_(2)\n",
    "net.conv1.bias.detach().zero_()\n",
    "\n",
    "# 构建两个列表用于保存信息\n",
    "fmap_block = []\n",
    "input_block = []\n",
    "\n",
    "def forward_hook(module, data_input, data_output):\n",
    "    fmap_block.append(data_output)\n",
    "    input_block.append(data_input)\n",
    "\n",
    "# 注册Hook\n",
    "net.conv1.register_forward_hook(forward_hook)\n",
    "\n",
    "# 输入数据\n",
    "fake_img = torch.ones((1, 1, 4, 4))\n",
    "output = net(fake_img)\n",
    "\n",
    "# 观察结果\n",
    "# 卷积神经网络输出维度和结果\n",
    "print(\"output share:{}\\noutput value:{}\\n\".format(output.size(),output))\n",
    "\n",
    "# 卷积神经网络Hook函数返回的结果\n",
    "print(\"feature map share:{}\\noutput value:{}\\n\".format(fmap_block[0].shape,fmap_block[0]))\n",
    "\n",
    "# 输入的信息\n",
    "print(\"input share:{}\\ninput value:{}\\n\".format(input_block[0][0].size(),input_block[0][0]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第一部分：实现词性标注任务，给定一个单词，通过RNN和LSTM模型输出单词的词性。\n",
    "\n",
    "所有数据都在data文件夹中，每个文件的命名即其词性。\n",
    "\n",
    "后续字符的编码，模型的搭建，模型的训练会给出一个参考baseline模版，同学们可以选择在此baseline模版下构建模型，也可以选择任意增删改这部分代码构建自己的模型并优化。（全部删除这部分代码，自己重新写也可以）\n",
    "\n",
    "同学们还可以考虑用CNN提取序列特征进行分类，此部分实现并在模型评价部分进行对比，会得到1-2分的附加分。如果觉得自己此部分特别优秀，可以添加注释对自己的工作进行详细描述。\n",
    "\n",
    "作业满分12分，其中2分为选做附加分。\n",
    "\n",
    "注意：\n",
    "\n",
    "* 为方便比较同学们的结果，读取数据并划分数据集这部分代码不可更改。\n",
    "\n",
    "* 模型评价部分要求分别输出RNN模型和LSTM模型在训练集和测试集上的正确率。**最终提交的版本必须已经正确显示这四个值，如果需要助教重新跑模型得到结果，会扣除2分**。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "from io import open\n",
    "import os, string, random, time, math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读取数据并划分数据集（勿更改代码）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def findFiles(path): \n",
    "    return glob.glob(path)\n",
    "tags = []\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "\n",
    "def readLines(filename):\n",
    "    lines = open(filename, encoding='utf-8').read().strip().split('\\n')\n",
    "    return lines\n",
    "\n",
    "for filename in findFiles('data/*.txt'):\n",
    "    language = os.path.splitext(os.path.basename(filename))[0]\n",
    "    if language not in tags:\n",
    "        tags.append(language)\n",
    "    lines = readLines(filename)\n",
    "    for line in lines:\n",
    "        X.append(line)\n",
    "        y.append(language)\n",
    "\n",
    "n_tags = len(tags)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state =10, stratify = y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "cQ8B7F9i--AV",
    "outputId": "10a2fbcc-e22e-41e1-d3be-72bf8550dff1"
   },
   "source": [
    "### 字符的编码"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本部分所有代码均可根据自己实现需要进行增删改，所给代码只是一种实现的参考模版。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 统计字符\n",
    "s = set()\n",
    "for path in findFiles('data/*.txt'):\n",
    "    f = open(path,\"r\")\n",
    "    for word in f.readlines():\n",
    "        for char in word:\n",
    "            s.add(char)\n",
    "    f.close()\n",
    "all_letters = \"\"\n",
    "for c in s:\n",
    "    all_letters+=str(c)\n",
    "\n",
    "n_letters = len(all_letters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hyes9BW7CTaU"
   },
   "outputs": [],
   "source": [
    "#function to create name representation\n",
    "\n",
    "def name_rep(name):\n",
    "    rep = torch.zeros(len(name), 1, n_letters)\n",
    "    for index, letter in enumerate(name):\n",
    "        pos = all_letters.find(letter)\n",
    "        rep[index][0][pos] = 1\n",
    "    return rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qvsscR5nE67_"
   },
   "outputs": [],
   "source": [
    "#function to create lang representation\n",
    "\n",
    "def nat_rep(lang):\n",
    "    return torch.tensor([tags.index(lang)], dtype = torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dataloader\n",
    "\n",
    "def dataloader(batch_size, X_, y_):\n",
    "    to_ret = []\n",
    "    for i in range(batch_size):\n",
    "        index_ = np.random.randint(len(X_))\n",
    "        name, lang = X_[index_], y_[index_] #get the data at the random index\n",
    "        to_ret.append((name, lang, name_rep(name), nat_rep(lang)))\n",
    "\n",
    "    return to_ret"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G8WWShboVpY0"
   },
   "source": [
    "### 模型的搭建"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本部分所有代码均可根据自己实现需要进行增删改，所给代码只是一种实现的参考模版。\n",
    "\n",
    "模型需要分别构建RNN和LSTM模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R3lAteTGSRky"
   },
   "outputs": [],
   "source": [
    "# TODO(4分)\n",
    "\n",
    "class RNN_net(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def forward(self, input_, hidden):\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "    def init_hidden(self):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO(4分)\n",
    "\n",
    "class LSTM_net(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def forward(self, input_, hidden):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def init_hidden(self):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型的训练\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本部分所有代码均可根据自己实现需要进行增删改，所给代码只是一种实现的参考模版。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to train the data\n",
    "\n",
    "def train_step(net, opt, criterion, batch_size):\n",
    "    \n",
    "    opt.zero_grad()\n",
    "    total_loss = 0\n",
    "    data_ = dataloader(batch_size, X_train, y_train)\n",
    "    for name, language, name_ohe, lang_rep in data_:\n",
    "\n",
    "        hidden = net.init_hidden()\n",
    "\n",
    "        for i in range(name_ohe.size()[0]):\n",
    "            output, hidden = net(name_ohe[i], hidden)\n",
    "            \n",
    "        loss = criterion(output, lang_rep)\n",
    "        loss.backward(retain_graph=True)\n",
    "        \n",
    "        total_loss += loss\n",
    "        \n",
    "    opt.step()       \n",
    "            \n",
    "    return total_loss/batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, lr = 0.01, steps = 100, batch_size = 10, momentum = 0.9, freq = 5):\n",
    "\n",
    "    # TODO(2分)\n",
    "    criterion = None \n",
    "    opt = None\n",
    "\n",
    "    loss_arr = np.zeros(steps)\n",
    "\n",
    "    #iterate through all the batches\n",
    "    for i in range(steps):\n",
    "        loss_arr[i] = train_step(net, opt, criterion, batch_size)\n",
    "        if (i+1)%freq==0: \n",
    "            print(\"Iteration number:\", i + 1,'Loss:', round(loss_arr[i],4))\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(loss_arr, \"-*\")\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.show()\n",
    "    print(\"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN训练\n",
    "n_hidden = 128\n",
    "rnn_net = RNN_net(n_letters, n_hidden, n_tags)\n",
    "train(rnn_net, lr = 0.0005, steps = 100, batch_size = 256)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM训练\n",
    "n_hidden = 128\n",
    "lstm_net = LSTM_net(n_letters, n_hidden, n_tags)\n",
    "train(lstm_net, lr = 0.0005, steps = 100, batch_size = 256)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MONZ_pPiZGnI"
   },
   "source": [
    "### 模型效果评价\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "分别输出RNN模型和LSTM模型在训练集和测试集上的正确率。**注意最终提交的版本必须已经正确显示这四个值，如果需要助教重新跑模型得到结果，会扣除2分。**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer(net, name):\n",
    "    net.eval()\n",
    "    name_ohe = name_rep(name)\n",
    "    hidden = net.init_hidden()\n",
    "\n",
    "    for i in range(name_ohe.size()[0]):\n",
    "        output, hidden = net(name_ohe[i], hidden)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nAGLmmwNacBY"
   },
   "outputs": [],
   "source": [
    "#create a function to evaluate model\n",
    "\n",
    "def eval_test(net):\n",
    "     correct = 0\n",
    "     for i in range(len(X_test)):\n",
    "        name,lang = X_test[i],y_test[i]\n",
    "        name_ohe = name_rep(name)\n",
    "        lang_rep = nat_rep(lang)\n",
    "        output = infer(net, name) \n",
    "        val, indices = output.topk(1) \n",
    "    \n",
    "        if indices == lang_rep:\n",
    "            correct += 1\n",
    "     accuracy = correct/len(X_test)\n",
    "\n",
    "     return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a function to evaluate model\n",
    "\n",
    "def eval_train(net):\n",
    "     correct = 0\n",
    "     for i in range(len(X_train)):\n",
    "        name,lang = X_train[i],y_train[i]\n",
    "        name_ohe = name_rep(name)\n",
    "        lang_rep = nat_rep(lang)\n",
    "        output = infer(net, name) \n",
    "        val, indices = output.topk(1) \n",
    "    \n",
    "        if indices == lang_rep:\n",
    "            correct += 1\n",
    "     accuracy = correct/len(X_train)\n",
    "\n",
    "     return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "BI5ItvwdXx3w",
    "outputId": "3e37ac9e-fc46-4231-bc58-de49d11d173e"
   },
   "outputs": [],
   "source": [
    "print(\"rnn结果\")\n",
    "print(\"train set accuracy:\"+str(round(eval_train(rnn_net),4)))\n",
    "print(\"test set accuracy:\"+str(round(eval_test(rnn_net),4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tWqm3pgUaJgl"
   },
   "outputs": [],
   "source": [
    "print(\"LSTM结果\")\n",
    "print(\"train set accuracy:\"+str(round(eval_train(lstm_net),4)))\n",
    "print(\"test set accuracy:\"+str(round(eval_test(lstm_net),4)))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Name2Nation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
